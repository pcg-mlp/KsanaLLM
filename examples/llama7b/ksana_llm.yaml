setting:
  global:
    tensor_para_size: 1
    pipeline_para_size: 1
    enable_lora_adapter: false
  batch_scheduler:
    waiting_timeout_in_ms: 600000
    max_waiting_queue_len: 100
    max_token_number: 4096
    max_batch_size: 4
    max_input_len: 1024
    max_output_len: 1024
  block_manager:
    block_token_num: 16
    reserved_device_memory_ratio: 0.01
    lora_deivce_memory_ratio: 0.0
    lora_host_memory_factor: 10.0
    block_device_memory_ratio: -1.0
    block_host_memory_factor: 10.0
model_spec:
  base_model:
    model_name: llama
    model_dir: /model/llama-ft/7B/1-gpu
  lora_models:
    - model_name: lora_1
      model_dir: /model/lora/lora_1/13B/2-gpu
